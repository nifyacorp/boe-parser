# BOE Analysis Service ğŸ”

A Node.js microservice that analyzes content from the BoletÃ­n Oficial del Estado (BOE) using AI. This service processes natural language queries against the latest BOE publications to extract relevant information and insights.

## Features

- ğŸ”„ Automatic daily BOE content fetching and parsing
- ğŸ¤– AI-powered content analysis for natural language queries (Gemini and OpenAI)
- ğŸ“Š Structured JSON responses with relevance scoring
- ğŸ” Secure API key authentication (can use Google Cloud Secret Manager)
- ğŸ“ Comprehensive logging system
- ğŸ“š Interactive API documentation
- â˜ï¸ Cloud-native design for Google Cloud Run
- ğŸ“¨ Publishes results to Google Cloud Pub/Sub

## Process Flow

The BOE-parser service uses an AI-driven approach to process Spanish Official Bulletin (BOE) content. Here's a detailed breakdown of the process:

```
                                BOE Parser Process Flow
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  â”‚     â”‚                   â”‚     â”‚                    â”‚     â”‚                  â”‚
â”‚  1. HTTP Request â”‚     â”‚ 2. BOE Retrieval  â”‚     â”‚  3. AI Analysis    â”‚     â”‚ 4. PubSub        â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€>â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚â”€â”€â”€â”€>â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚â”€â”€â”€â”€>â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
â”‚                  â”‚     â”‚                   â”‚     â”‚                    â”‚     â”‚                  â”‚
â”‚ - Subscription   â”‚     â”‚ - Fetch BOE XML   â”‚     â”‚ - Create prompts   â”‚     â”‚ - Format results â”‚
â”‚ - Search prompts â”‚     â”‚ - Parse content   â”‚     â”‚ - Process with AI  â”‚     â”‚ - Add metadata   â”‚
â”‚ - User metadata  â”‚     â”‚ - Structure data  â”‚     â”‚ - Extract matches  â”‚     â”‚ - Publish messageâ”‚
â”‚                  â”‚     â”‚                   â”‚     â”‚ - Score relevance  â”‚     â”‚                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                                        â”‚
                                                                                        â”‚
                                                                                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        â”‚     â”‚                        â”‚     â”‚                        â”‚
â”‚  7. User Notification  â”‚     â”‚  6. DB Storage        â”‚     â”‚  5. Notification Worker â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚<â”€â”€â”€â”€â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚<â”€â”€â”€â”€â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€      â”‚
â”‚                        â”‚     â”‚                        â”‚     â”‚                        â”‚
â”‚ - Email/push           â”‚     â”‚ - Create notification  â”‚     â”‚ - Process PubSub msg   â”‚
â”‚ - In-app alert         â”‚     â”‚   records              â”‚     â”‚ - Extract matches      â”‚
â”‚ - Result display       â”‚     â”‚ - Associate with user  â”‚     â”‚ - Parse content        â”‚
â”‚                        â”‚     â”‚   and subscription     â”‚     â”‚                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Process Steps:

1. **Request Processing:**
   - The service receives a request with search prompts (text queries)
   - The request includes user identification and subscription data
   - The controller validates the request format and authorization

2. **BOE Content Retrieval:**
   - The parser service fetches the BOE content for a specific date (or today's by default)
   - It uses a scraper module to fetch BOE XML data from oficial sources
   - The XML is parsed into a structured format with sections, departments, and items
   - This creates a dataset of BOE bulletins/announcements for analysis

3. **AI Processing:**
   - The service routes the BOE items and prompts to the AI service
   - By default, it uses Google's Gemini AI (or OpenAI as an alternative)
   - The AI service prepares specialized prompts:
     - A **system prompt** that explains the task
     - A **content prompt** that contains the BOE items and user query
   - The AI model analyzes the data and returns JSON with:
     - Relevance scores for each match (0-100 scale)
     - Generated summaries of matched content
     - Notification-friendly titles
     - Links and metadata for each match

4. **PubSub Publication:**
   - The formatted results are published to Google PubSub
   - This message includes all the matches found, relevance scores, and metadata
   - The structured JSON format allows for easy downstream processing

5. **Notification Worker:**
   - A separate microservice consumes the PubSub message
   - It processes the matches and prepares notifications

6. **Database Storage:**
   - Notifications are stored in the database
   - They're associated with the correct user and subscription

7. **User Notification:**
   - Users are notified about relevant BOE entries based on their subscriptions
   - Notifications can be viewed in the application or sent as emails/alerts

The key innovation in this process is that the AI is prompted to return structured data (JSON) rather than natural language. This allows the service to directly use the AI's output in the application pipeline without complex post-processing.

## Architecture

The service follows a modular architecture with clear separation of concerns:

### Updated Directory Structure (approx.)

```plaintext
src/
â”œâ”€â”€ index.js              # Application entry point
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.js         # Configuration loading (env vars, secrets)
â”œâ”€â”€ routes/
â”‚   â”œâ”€â”€ index.js          # Main router aggregation
â”‚   â”œâ”€â”€ analyze.js        # Analysis endpoint routes
â”‚   â””â”€â”€ test.js           # Test endpoint routes
â”œâ”€â”€ controllers/
â”‚   â”œâ”€â”€ analyze.js        # Controller for analysis logic
â”‚   â””â”€â”€ test.js           # Controller for test endpoints
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ ai/               # AI Service Facade & Implementations
â”‚   â”‚   â”œâ”€â”€ index.js      # Facade (chooses Gemini/OpenAI)
â”‚   â”‚   â”œâ”€â”€ client.js     # AI client initialization (Gemini/OpenAI)
â”‚   â”‚   â”œâ”€â”€ gemini.js     # Gemini specific logic
â”‚   â”‚   â”œâ”€â”€ openai.js     # OpenAI specific logic
â”‚   â”‚   â””â”€â”€ prompts/      # Directory for AI prompts
â”‚   â””â”€â”€ parser/           # BOE Parsing Service
â”‚       â”œâ”€â”€ index.js      # Orchestrates fetching/parsing
â”‚       â”œâ”€â”€ scraper.js      # Fetches BOE XML/HTML
â”‚       â””â”€â”€ textProcessor.js # Text cleaning utilities
â”œâ”€â”€ middleware/
â”‚   â”œâ”€â”€ index.js          # Middleware registration
â”‚   â”œâ”€â”€ auth.js           # API key authentication
â”‚   â”œâ”€â”€ errorHandler.js   # Global error handler
â”‚   â”œâ”€â”€ requestId.js      # Adds request ID
â”‚   â””â”€â”€ validation.js     # Request body validation
â””â”€â”€ utils/
    â”œâ”€â”€ pubsub.js         # Google Cloud Pub/Sub interaction
    â”œâ”€â”€ secrets.js        # Google Cloud Secret Manager interaction
    â””â”€â”€ errors/           # Custom error classes
        â””â”€â”€ AppError.js
```

### Key Components

- **Express Server**: REST API endpoints and request handling
- **BOE Scraper**: Intelligent parsing of BOE publications
- **Text Processor**: Query optimization and normalization
- **AI Analyzer**: Advanced content analysis
- **Auth System**: Secure API key validation
- **Logger**: Structured logging with detailed context
- **Secret Manager**: Secure credential management

## Testing the Service

### Using the CLI Test Script

A test script is provided to easily test the BOE parser's PubSub integration:

```bash
# Run with mock data (fast)
node test-pubsub.js --skipAI

# Run with real AI processing (slower)
node test-pubsub.js

# Publish results to PubSub for end-to-end testing
node test-pubsub.js --publish

# Use custom prompts
node test-pubsub.js --prompt="Ayuntamiento Barcelona" --prompt="Subvenciones cultura"

# Get help
node test-pubsub.js --help
```

### Manual Testing

To test the BOE parser manually:

1. Test the health endpoint:
   ```
   curl http://localhost:8080/health
   ```

2. Test the PubSub endpoint with mock data:
   ```
   curl -X POST http://localhost:8080/test-pubsub \
     -H "Content-Type: application/json" \
     -H "Authorization: Bearer test-api-key" \
     -d '{"texts":["Ayuntamiento Barcelona licitaciones"], "skipAI": true}'
   ```

3. Test with real AI processing and publish to PubSub:
   ```
   curl -X POST http://localhost:8080/test-pubsub \
     -H "Content-Type: application/json" \
     -H "Authorization: Bearer test-api-key" \
     -d '{"texts":["Ayuntamiento Barcelona licitaciones"], "publishToPubSub": true}'
   ```

## Prerequisites

- Node.js (v18 or higher recommended)
- npm
- Google Cloud Project (for Pub/Sub, Secret Manager, Cloud Run)
- Docker (optional, for containerized deployment)

## Environment Variables

This service relies on environment variables for configuration. For local development, create a `.env` file in the root directory by copying `.env.example`.

### Required

These variables **must** be set for the application to function correctly.

| Variable | Description | Example Value |
|---|---|---|
| `GOOGLE_CLOUD_PROJECT` | Your Google Cloud Project ID. | `my-gcp-project-id` |
| `PUBSUB_TOPIC_NAME` | The Pub/Sub topic ID where analysis results are published. | `processor-results` |
| `GEMINI_API_KEY` | API Key for Google AI (Gemini). **See note below.** | `AIza...` |
| `OPENAI_API_KEY` | API Key for OpenAI. **See note below.** | `sk-...` |
| `API_KEY` | The secret key clients must provide in the `Authorization: Bearer <key>` header. **See note below.** | `my-secret-bearer-token` |

**Note on API Keys / Secrets:** The application loads sensitive keys (`GEMINI_API_KEY`, `OPENAI_API_KEY`, `API_KEY`) using the following priority order:
1.  **Environment Variable:** Checks `process.env.VAR_NAME` directly.
2.  **Mounted Secret File:** Checks for a file at `/etc/secrets/VAR_NAME` (standard path for secrets mounted via `--set-secrets` in Cloud Run).
3.  **Secret Manager API (Production Only):** If running with `NODE_ENV=production` AND the key wasn't found via the methods above, it attempts to fetch the secret named `VAR_NAME` from Google Cloud Secret Manager using its API. Requires the service account to have the Secret Manager Secret Accessor role.

Therefore, you can provide these keys either as regular environment variables (`--set-env-vars`) or, more securely, by mounting them from Secret Manager (`--set-secrets=ENV_VAR_NAME=SECRET_NAME:latest`).

### Optional

These variables have default values but can be overridden.

| Variable | Description | Default |
|---|---|---|
| `NODE_ENV` | Environment mode (`development` or `production`). Affects logging, secret loading. | `development` |
| `PORT` | Port the server listens on. Cloud Run injects its own. | `3000` |
| `PUBSUB_DLQ_TOPIC_NAME` | The Pub/Sub topic ID for publishing errors/DLQ messages. | `${PUBSUB_TOPIC_NAME}-dlq` |
| `GEMINI_MODEL` | The specific Gemini model to use. | `gemini-1.5-pro` |
| `OPENAI_MODEL` | The specific OpenAI model to use. | `gpt-4o-mini` |
| `OPENAI_ORGANIZATION` | OpenAI Organization ID (if applicable). | *empty* |
| `SCRAPER_TIMEOUT_MS` | Timeout in milliseconds for fetching BOE content. | `15000` |
| `SCRAPER_USER_AGENT` | User-Agent string for the BOE scraper. | `BOE Parser Bot/1.0` |

## Setup

1.  Clone the repository:
    ```bash
    git clone [repository-url]
    cd boe-parser # Or your project directory name
    ```

2.  Install dependencies:
    ```bash
    npm install
    ```

3.  Configure Environment:
    *   Copy `.env.example` to `.env`.
    *   Fill in the required values in `.env` (especially API keys for local testing).
    *   **For Production/Cloud Run:** Set the required environment variables in the Cloud Run service configuration. If using Secret Manager for API keys, ensure the secrets exist and the Cloud Run service account has the "Secret Manager Secret Accessor" IAM role.

## Running Locally

```bash
# Start the server (using .env variables)
npm start

# Start in development mode with auto-reloading
npm run dev
```

The server will typically start on port 3000 (or the `PORT` specified).

## Deployment (Google Cloud Run Example)

1.  Ensure your `gcloud` CLI is configured (project, authentication).
2.  Push the image to Google Artifact Registry (or Container Registry):
    ```bash
    # Replace REGION and PROJECT_ID
    gcloud builds submit --tag REGION-docker.pkg.dev/PROJECT_ID/boe-parser/boe-parser-image:latest
    ```
3.  Deploy to Cloud Run:
    ```bash
    # Replace REGION, PROJECT_ID, and set appropriate variables
    gcloud run deploy boe-parser-service \
      --image REGION-docker.pkg.dev/PROJECT_ID/boe-parser/boe-parser-image:latest \
      --platform managed \
      --region REGION \
      --project PROJECT_ID \
      --allow-unauthenticated \ # Or configure authentication
      --set-env-vars NODE_ENV=production,GOOGLE_CLOUD_PROJECT=PROJECT_ID,PUBSUB_TOPIC_NAME=processor-results,PUBSUB_DLQ_TOPIC_NAME=processor-results-dlq \ # Add other OPTIONAL vars if needed
      # Set secrets if using Secret Manager for API Keys (replace SECRET_NAME with actual secret name)
      --set-secrets=GEMINI_API_KEY=GEMINI_API_KEY:latest,OPENAI_API_KEY=OPENAI_API_KEY:latest,API_KEY=API_KEY:latest
    ```
    *   Adjust `--allow-unauthenticated` based on your needs.
    *   Use `--set-env-vars` for non-sensitive configuration.
    *   Use `--set-secrets` to securely mount secrets from Secret Manager as environment variables. The format is `ENV_VAR_NAME=SECRET_NAME:VERSION`. Use the actual name of your secret in Secret Manager.

## API Endpoints

(Refer to `ENDPOINTS.md` or previous sections for details - keep this concise)

-   `GET /health`: Health check.
-   `POST /api/analyze-text`: Main analysis endpoint (Requires `Authorization: Bearer <API_KEY>`).
-   `GET /api/check-gemini`: Test Gemini connection (Requires Auth).
-   `GET /api/check-openai`: Test OpenAI connection (Requires Auth).
-   `POST /api/test-pubsub`: Test publishing a mock message (Requires Auth).

## Development

```bash
# Run linting checks
npm run lint

# Run tests (if configured in package.json)
npm test
```

## Security

- API key authentication
- Secure secret management
- Input validation
- Rate limiting
- Error logging

## License